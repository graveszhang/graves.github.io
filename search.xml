<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Active Learning 实战</title>
    <url>/2020/04/12/Active-Learning-%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h2><ol>
<li>使用keras搭建AlexNet对ImageNet的数据集进行训练</li>
<li>使用训练模型对于所有候选集中的样本进行预测（10个一组）</li>
<li>计算Entropy和Diversity分数，选取前50%进行标注并训练新的CNN</li>
<li>重复2和3，直到3所得模型的预测准确率达到预期标准（85%）</li>
</ol>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>Active Learning</tag>
        <tag>Neural Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Learning Neural Network/Conv NN</title>
    <url>/2020/03/15/Learning-Neural-Network-Conv-NN/</url>
    <content><![CDATA[<h2 id="Neural-Networks"><a href="#Neural-Networks" class="headerlink" title="Neural Networks"></a>Neural Networks</h2><h3 id="Neurons"><a href="#Neurons" class="headerlink" title="Neurons"></a>Neurons</h3><ol>
<li>Each input (x1, x2) is multipled by a weight</li>
<li>All weighted inputs are added with bias b</li>
<li>The sum is passed through an <strong>activation function</strong></li>
</ol>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/WX20200312-211909%402x.png"/>
<a id="more"></a>
### Combining Neurons into Neural Network: Feedforward
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/WX20200315-110025%402x.png"/>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">  <span class="comment"># Define weights and bias for the first layer</span></span><br><span class="line">  weights = np.array([<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">  bias = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># The Neuron class here is from the previous section</span></span><br><span class="line">  self.h1 = Neuron(weights, bias)</span><br><span class="line">  self.h2 = Neuron(weights, bias)</span><br><span class="line">  self.o1 = Neuron(weights, bias)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feedforward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">  <span class="comment"># x = np.array([2,3]) </span></span><br><span class="line">  out_h1 = self.h1.feedforward(x)</span><br><span class="line">  out_h2 = self.h2.feedforward(x)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># The inputs for o1 are the outputs from h1 and h2</span></span><br><span class="line">  out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> out_o1</span><br></pre></td></tr></table></figure>
<h3 id="Loss-Mean-Squared-Loss"><a href="#Loss-Mean-Squared-Loss" class="headerlink" title="Loss: Mean Squared Loss"></a>Loss: Mean Squared Loss</h3><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/mse.png"/>
- n is the number of samples
- y represents the variables being predicted
- y_true is the true value of the variable
- y_pred is the predicted value of the variable, also the **output of our network**
- (y_true - y_pred)^2 is known as **squared error**

<h3 id="Back-Propagation"><a href="#Back-Propagation" class="headerlink" title="Back Propagation"></a>Back Propagation</h3><p>On one note, idea is use chain rule to calculate the partial derivative of loss function and the input.</p>
<h3 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent(SGD)"></a>Stochastic Gradient Descent(SGD)</h3><ul>
<li>Main idea: Change our weights and biases to minimize loss and improve the network</li>
<li>Update Equation<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/update.png"/>
\mu is a constant called learning rate that controls how **fast** we train.</li>
<li>If the second term is positive, w1 will decrease, which make L decrease</li>
<li>If the second term is negative, w1 will increase, which make L decrease</li>
</ul>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><h3 id="Convolution-Layers"><a href="#Convolution-Layers" class="headerlink" title="Convolution Layers"></a>Convolution Layers</h3><p>A classic use case of CNNs is to perform image classification. The reason not to use a normal Neural Network:</p>
<ul>
<li>Images are big.</li>
<li>Positions can change.</li>
</ul>
<p>The difference between Convolution Neural Network and normal ones is that CNN uses <strong>Convolutional layers</strong> which is based on mathematical operation of convolution.</p>
<p>Nomrally CNN consists of multiple filters, and we produce a output inmage by <strong>convolving</strong> the filter with the input image.</p>
<blockquote>
<p>Side Note: We (along with many CNN implementations) are technically actually using cross-correlation instead of convolution here, but they do almost the same thing. </p>
</blockquote>
<p>Consider the following example:<br><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/cnn.png"/></p>
<p>The numbers in the image represent pixel intensities, where 0 is black and 255 is white. We’ll convolve the input image and the filter to produce a <strong>2x2 output image</strong>.</p>
<p>To start, we overlap the filter in the top-left corner of the image.<br><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/cnnf1.png"/></p>
<p>Next, we perform element-wise multiplication between the overlapping image values and filter values. </p>
<p>Then we sum up the results and put the result onto the output matrix and do the same to the rest.<br><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/convolve-output.gif"/></p>
<blockquote>
<p>What’s the usage? Filter can help people look for <strong>specific localized image features</strong>. The above filter we used in example is known as <strong>Sobel filter</strong>. It is edge-detector, which can be horizontal or vertical.<br><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/vertical_sobel.png"/></p>
</blockquote>
<ul>
<li><p>Padding: Add 0 to the surroundings, like below</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/padding.png"/>
</li>
<li><p>CNN includes conv layers that use a set of filters to turn input images into output images. A conv layer’s primary parameter is the number of filters it has. </p>
</li>
</ul>
<blockquote>
<p>For a nxn image, if used a conv layer with 8 filters and valid padding, the output will be (n-2)x(n-2)x8</p>
</blockquote>
<h3 id="Implement-Convolution"><a href="#Implement-Convolution" class="headerlink" title="Implement Convolution"></a>Implement Convolution</h3><p>A conv layey’s feedforward.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conv3x3</span>:</span></span><br><span class="line">  <span class="comment"># A Convolution layer using 3x3 filters.</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_filters)</span>:</span></span><br><span class="line">    self.num_filters = num_filters</span><br><span class="line"></span><br><span class="line">    <span class="comment"># filters is a 3d array with dimensions (num_filters, 3, 3)</span></span><br><span class="line">    <span class="comment"># We divide by 9 to reduce the variance of our initial values</span></span><br><span class="line">    self.filters = np.random.randn(num_filters, <span class="number">3</span>, <span class="number">3</span>) / <span class="number">9</span></span><br><span class="line">    </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">iterate_regions</span><span class="params">(self, image)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Generates all possible 3x3 image regions using valid padding.</span></span><br><span class="line"><span class="string">    - image is a 2d numpy array</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    h, w = image.shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(h - <span class="number">2</span>):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(w - <span class="number">2</span>):</span><br><span class="line">        im_region = image[i:(i + <span class="number">3</span>), j:(j + <span class="number">3</span>)]</span><br><span class="line">        <span class="keyword">yield</span> im_region, i, j</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Performs a forward pass of the conv layer using the given input.</span></span><br><span class="line"><span class="string">    Returns a 3d numpy array with dimensions (h, w, num_filters).</span></span><br><span class="line"><span class="string">    - input is a 2d numpy array</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    h, w = input.shape</span><br><span class="line">    output = np.zeros((h - <span class="number">2</span>, w - <span class="number">2</span>, self.num_filters))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> im_region, i, j <span class="keyword">in</span> self.iterate_regions(input):</span><br><span class="line">      output[i, j] = np.sum(im_region * self.filters, axis=(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">		<span class="comment"># This line accutually performs the convolution</span></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<ul>
<li>We have <code>im_region</code>, a 3x3 array containing the relevant image region.</li>
<li>We have <code>self.filters</code>, a 3d array.</li>
<li>We do <code>im_region * self.filters</code>, which uses numpy’s <a href="https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html" target="_blank" rel="noopener">broadcasting</a> feature to element-wise multiply the two arrays. The result is a 3d array with the same dimension as <code>self.filters</code>.</li>
<li>We <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html" target="_blank" rel="noopener">np.sum()</a> the result of the previous step using <code>axis=(1, 2)</code>, which produces a 1d array of length <code>num_filters</code> where each element contains the convolution result for the corresponding filter.</li>
<li>We assign the result to <code>output[i, j]</code>, which contains convolution results for pixel <code>(i, j)</code> in the output.</li>
</ul>
<h3 id="Pooling"><a href="#Pooling" class="headerlink" title="Pooling"></a>Pooling</h3><p>Reduce the size of an image by usng simple technique like max, min, average… e.g.</p>
<ul>
<li>Max pooling: we traverse the input image in 2x2 blocks (because pool size = 2) and put the max value into the output image at the corresponding pixel.</li>
<li>Pooling divides the input’s width and height by the pool size.</li>
</ul>
<h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MaxPool2</span>:</span></span><br><span class="line">  <span class="comment"># A Max Pooling layer using a pool size of 2.</span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">iterate_regions</span><span class="params">(self, image)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Generates non-overlapping 2x2 image regions to pool over.</span></span><br><span class="line"><span class="string">    - image is a 2d numpy array</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    h, w, _ = image.shape</span><br><span class="line">    new_h = h // <span class="number">2</span></span><br><span class="line">    new_w = w // <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(new_h):</span><br><span class="line">      <span class="keyword">for</span> j <span class="keyword">in</span> range(new_w):</span><br><span class="line">        im_region = image[(i * <span class="number">2</span>):(i * <span class="number">2</span> + <span class="number">2</span>), (j * <span class="number">2</span>):(j * <span class="number">2</span> + <span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">yield</span> im_region, i, j</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    Performs a forward pass of the maxpool layer using the given input.</span></span><br><span class="line"><span class="string">    Returns a 3d numpy array with dimensions (h / 2, w / 2, num_filters).</span></span><br><span class="line"><span class="string">    - input is a 3d numpy array with dimensions (h, w, num_filters)</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    h, w, num_filters = input.shape</span><br><span class="line">    output = np.zeros((h // <span class="number">2</span>, w // <span class="number">2</span>, num_filters))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> im_region, i, j <span class="keyword">in</span> self.iterate_regions(input):</span><br><span class="line">      output[i, j] = np.amax(im_region, axis=(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>





<h2 id="实验-Hands-on"><a href="#实验-Hands-on" class="headerlink" title="实验 Hands-on"></a>实验 Hands-on</h2><ul>
<li>正例：预测值和真实值都为1</li>
<li>负例：预测值和真实值都为0</li>
</ul>
]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Neural Network</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis: Actively and Incrementally</title>
    <url>/2020/02/22/Fine-tuning-Convolutional-Neural-Networks-for-Biomedical-Image-Analysis-Actively-and-Incrementally/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在生物医学图像分析的领域中，一直有应用卷积神经网络（CNN）强烈呼声，但由于在生物医学成像中缺少大型注释数据集，因而阻碍了其进行。注释生物医学图像不仅繁琐且耗时，而且要求昂贵的面向专业的知识和技能，而这些知识和技能不容易获得。为了降低注释成本，本文提出了一种称为AIFT（主动，增量式微调）的新颖方法，可以将主动学习和转移学习自然地整合到单个框架中。 AIFT从经过预先训练的CNN开始，从未注释的样本中寻找“有价值的”样本进行注释，并且CNN会在每次迭代中合并新注释的样本，进一步进行连续的微调，从而逐步提高CNN的性能。我们已经在三种不同的生物医学成像应用中评估了我们的方法，证明了注释的成本可以减少至少一半。该性能归因于AIFT方法先进的主动（active）和增量（incremental）功能所带来的若干优势。</p>
<a id="more"></a>

<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>普通的主动学习和深度学习的文献丰富而深刻，然而，旨在将主动学习与深度学习相结合的研究很少：Wang和Shang 可能是第一个将主动学习与深度学习相结合的研究者，他们的方法基于堆叠式受限Boltzmann机器和堆叠式自动编码器。对于高光谱图像分类，也报道了类似的想法。斯塔克应用主动学习来提高CNNs对CAPTCHA识别的性能，而Al Rahhal等人利用深度学习进行主动心电图分类。所有这些方法与本文提出的AIFT方法不同，在于它们在每次迭代中都反复从头开始对学习者进行了重新培训，而AIFT以递增的方式连续微调（微调的）CNN，具有以下优点</p>
<ol>
<li>从完全空白的标记数据集开始，不需要任何初始种子标记的样本</li>
<li>通过持续不断地提高学习者的能力进行微调，而不是反复进行重新训练</li>
<li>自然地利用预期的一致性，通过每个和candidate相关的patch选择样本“有价值”的标签</li>
<li>在选择过程中自动处理noise</li>
<li>在每个candidate上计算熵和多样性，从而节省了大量计算时间</li>
</ol>
<h3 id="AIFT算法"><a href="#AIFT算法" class="headerlink" title="AIFT算法"></a>AIFT算法</h3><p>本文基于计算机辅助诊断的生物医学成像（CAD）背景下提出AIFT方法。 CAD系统通常具有候选生成器，该生成器可以快速生成一组候选，其中有些是阳性，有些是阴性。在生成候选者之后，需要训练一个分类器，以消除尽可能多的错误，同时保持尽可能高的正确率。要训练分类器，必须为每个候选人贴上标签。我们假设每个candidate从$| Y |$个标签中选择一个可能的标签，为了提高CAD的CNN的性能，通常会通过数据增强为每个候选自动生成多个patch。</p>
<p>所有标签都是在候选级别上获取的，用数学来表示即给定一组候选$U = {C_1，C_2，…，C_n}$，其中n是候选数，每个候选$C_i = {x_i^1，x^2_i，…，x^m_i}$都有m个相关联的patch，下面的算法会迭代地选出一组候选的标签。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/ml-alg1.png"/>

<h4 id="持续微调过程"><a href="#持续微调过程" class="headerlink" title="持续微调过程"></a>持续微调过程</h4><p>一开始标记的数据集L为空，输入采用经过预训练的CNN（例如AlexNet），直接在候选的集合U上运行，选择b个candidate label。新标记的候选将被合并到L中，以逐步对CNN进行微调，直到性能令人满意为止。</p>
<h4 id="主动候选选择"><a href="#主动候选选择" class="headerlink" title="主动候选选择"></a>主动候选选择</h4><p>主动学习的关键是要制定一个标准来确定要注释的候选人的“价值”。我们的标准基于以下观察：从同一个候选者生成的所有补丁有相同的label，目前的CNN对它们会有相似的预测。它们的熵和多样性为提高当前CNN的性能的候选人的权重提供了有用的指标。从直觉上讲，熵代表的是分类的不确定程度，而多样性则表明候选者中补丁之间的预测一致性，而更高的多样性值表示候选者中补丁之间的预测不一致程度更高。因此，具有更高熵和更高多样性的候选人有望在提高当前CNN的表现方面做出更大贡献。形式上，假设当前CNN对patch$x^j_i$的预测是$p^j_i$，我们将其熵定义为：</p>
<p>$e_{i}^{j}=-\sum_{k=1}^{|Y|} p_{i}^{j, k} \log p_{i}^{j, k}$</p>
<p>我们定义对候选$C_i$的两个patch$x_i^j$和$x_i^l$中的多样性为：</p>
<p>$d_{i}(j, l)=\sum_{k=1}^{|Y|}\left(p_{i}^{j, k}-p_{i}^{l, k}\right) \log \frac{p_{i}^{j, k}}{p_{i}^{l, k}}$</p>
<p>熵$e^j_i$表示由未标记池中的候选$C_i$的补丁$x^j_i$所提供的信息，多样性$d_i（j，l）$估计了候选$C_i$的补丁$x^j_i$和$x^l_i$之间的信息重叠量。根据定义，$e^j_i$和$d_i(j,l)$中的所有条目均为非负数。此外，$d_i(j, j)=0，\forall j$，因此，为简化符号起见，我们将每个candidate的$e^j_i$和$d_i(j,l)$组合成一个矩阵Ri：</p>
<p>$R_{i}(j, l)=\left{\begin{array}{ll}{\lambda_{1} e_{i}^{j}} &amp; {\text { if } j=l} \ {\lambda_{2} d_{i}(j, l)} &amp; {\text { otherwise }}\end{array}\right.$</p>
<p>为方便起见，我们使用两个参数$\lambda_1,\lambda_2$，以便在实验过程中轻松打开/关闭熵或多样性。</p>
<h4 id="通过多数选择处理噪音"><a href="#通过多数选择处理噪音" class="headerlink" title="通过多数选择处理噪音"></a>通过多数选择处理噪音</h4><p>自动的数据扩充对于提高CNN的性能至关重要，但它不可避免地为一些候选者生成”硬”样本，如Figure 1和Figure 2（c）所示，从而注入嘈杂的标签。因此，为了显著提高我们方法的鲁棒性，我们需要计算熵和多样性，方法是只选择每个候选项的与当前 CNN 的预测保持一致的补丁。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/ml-fig1.png"/>

<p>对于每个候选 $C_i$，我们首先计算其所有修补程序的平均概率预测：$a_{i}=\frac{1}{m} \sum_{j=1}^{m} p_{i}^{j}$，这里m是每个候选的补丁数，p是补丁x的概率。</p>
<h4 id="预测模式的说明"><a href="#预测模式的说明" class="headerlink" title="预测模式的说明"></a>预测模式的说明</h4><p>假设当前 CNN 预测补丁 $x^j_i$的结果是 $p^j_i$，我们将 $p^j_i$ 的直方图($ j = [1,m]$)称为候选 $C_i$ 的预测模式，一共有七种典型的预测模式，下表列出了主动选择中的7种预测模式和6种AIFT方法之间的关系。我们假设一个候选人有11个补丁，并且他们由CNN预测的结果被列在第2栏。AIFT 熵、多样性和 熵 + 多样性根据前或后$\alpha$百分率的人计算。在此图中，我们定义多数选择为为 1/4。每种方法的第一选择以黄色突出显示，第二个选项以浅黄色突出显示。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/ml-pred.png"/>

<p>主动选择的七种预测模式分别是：</p>
<ul>
<li><p>模式 A：补丁的预测大多在0.5，具有更高的不确定性。大多数的主动学习算法倾向于这种类型的候选，因为它善于减少不确定性。</p>
</li>
<li><p>模式 B：它比模式 A 更平坦，因为补丁的预测从 0 到 1 广泛分布，产生更高的不一致程度。由于属于候选项的所有补丁都是通过数据放大生成的，因此它们（至少大多数）预计将有类似的预测。这种类型的候选很有可能极大提升CNN的表现。</p>
</li>
<li><p>模式 C：补丁在两端聚集，从而产生更高的多样性。这种类型的候选者最有可能与噪音相关联。这种模式在主动选择中最不利，因为它可能会导致微调 CNN 时出现混淆。</p>
</li>
<li><p>模式 D 和 E：修补程序的预测在一端（即 0 或 1）具有更高的确定性。现阶段对这类候选的注释应该推迟，因为CNN可能已经做出了正确的预测，而这类预测模式对微调帮助很小。未来这些候选者可能会演变为值得注意的模式，并进行更微小的调整。</p>
</li>
<li><p>模式F和G：在一些补丁的预测中，它们具有更高的确定度，并且与补丁预测中的一些异常值一致。他们能够地改善CNN的表现。</p>
</li>
</ul>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>本文主要将提出的方法应用于三种不同应用，包括结肠镜框分类、息肉检测和肺栓塞 （PE） 检测。我们的 AIFT 算法基于预先训练的 AlexNet 模型在 Caffe 工作中实现。在下面，我们将评估 AIFT 的六个变量（主动增量微调），包括多样性1/4（我们在每个候选项的 1/4 个补丁上实现多样性）（在每个候选的所有补丁上使用多样性）、熵1/4、 熵，（熵+多样性）1/4，（恩-营养+多样性），并将其与IFT随机（增量微调）和从零开始学习进行比较。</p>
<h4 id="结肠镜框分类"><a href="#结肠镜框分类" class="headerlink" title="结肠镜框分类"></a>结肠镜框分类</h4><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/ml-fig2.png"/>

<p>对结肠镜检查程序进行客观的质量评估对于确保高质量的结肠镜检查至关重要。结肠镜视频通常包含大量非信息性图像，结肠可视化效果较差，不适合检查结肠或执行治疗操作。视频中非信息性图像的分数越大，结肠可视化的质量越低，结肠镜检查的质量越低。因此，测量结肠镜检查过程质量的一种方法是监视捕获的图像的质量。从技术上讲，结肠镜检查的图像质量评估可以表述为图像分类任务，可以把输入图像分为有信息性或无信息性。</p>
<p>在实验中，4000个结肠镜帧是从6个完整的结肠镜视频中选出的。然后，经过培训的专家手动将收集的图像标记分类。一位胃肠病学家会进一步查看标记过的图像。视频中的标记帧被分为训练和测试组，每个帧包含大约 2000 个结肠镜镜帧。为了扩充数据，我们提取了21个补丁。</p>
<p>在所有三个应用程序中，我们的 AIFT 从空训练数据集开始，直接使用在 ImageNet 上预先训练的 AlexNet。结果如下</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/ml-fig3.png"/>

<p>第一步（查询了 2 个标签）结束，IFT Random 表现最好。有两个可能的原因：（1） 随机选择提供与测试数据集兼容的正负比的样本（2） 预先训练的 AlexNet 对我们的数据集进行了较差的预测，因为它是由自然图像而不是生物医学图像训练的。其输出概率大多混淆甚至不正确，导致选择分数不佳。但是AIFT在多样性1/4，熵1/4在第一次微调后迅速超越IFT随机，因为他们选择了重要的样本进行微调，使得训练过程比从剩余的训练数据集中随机选择更有效。AIFT 熵和多样性1/4 只有 4 个标签查询，可以使用 18 个标签查询实现 IFT 随机的每次形式，使用 22 个随机选择的帧实现从零学习。因此，IFT 随机可以节省超过 75% 的标签成本，节省了80% 的标签成本。</p>
<h4 id="息肉检测"><a href="#息肉检测" class="headerlink" title="息肉检测"></a>息肉检测</h4><p>暂无</p>
<h4 id="肺栓塞检测"><a href="#肺栓塞检测" class="headerlink" title="肺栓塞检测"></a>肺栓塞检测</h4><p>暂无</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在现实世界中，数据集通常是不平衡的。为了达到良好的分类性能，在训练中应同时使用每一类的样本。在患者水平上贴上标签肯定会降低注释成本，但会引入更严重的标签噪声，补丁级别的标签将更好的处理标签噪声，但会带来更重的标签负担。我们相信，在候选级别上进行标记在我们的三个应用中提供了合理的平衡。</p>
<p>在本文中，我们只使用熵和多样性作为标准。从理论上讲，可以设计大量的主动分离方法，但一共只有七种基本的预测模式。因此，我们可以只是专注于比较七种模式的差异，而不是方法的选择。一个特定模式可以选择多种方法：例如，熵、高斯距离和标准去维化可以应用在模式 A，而分集、方差和背离可以使用模式 C。我们认为每个组内使用各种方法带来的性能差异不会太大，临床实际使用的方法需要根据真实数据集在进行评估。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>data</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Online Machine Learning在众包中的应用</title>
    <url>/2020/02/19/%E6%8E%A2%E7%A9%B6%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0online%20learning%E5%9C%A8%E4%BC%97%E5%8C%85%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h3 id="众包中常见的机器学习算法"><a href="#众包中常见的机器学习算法" class="headerlink" title="众包中常见的机器学习算法"></a>众包中常见的机器学习算法</h3><h4 id="Active-Learning"><a href="#Active-Learning" class="headerlink" title="Active Learning"></a>Active Learning</h4><p>主动学习可以有效过滤或选择要由主管标记的样本，它成功应用于大量的计算任务，例如文本分类，图像识别或单词歧义消除场景。在众包中可以选择更好的未分类数据加快学习过程和减少人工的标签工作。</p>
<h4 id="Online-Learning"><a href="#Online-Learning" class="headerlink" title="Online Learning"></a>Online Learning</h4><p>在线学习也叫作incremental 或是 out-of-core learning [1] ，是机器学习的一个子领域，他最大的特点是接受动态输入。它使用实时的(时序的)数据并将其应用到机器学习算法中。在线机器学习需要有一个为其提供实时数据流的网站。</p>
<a id="more"></a>

<p>[1] <a href="https://medium.com/value-stream-design/online-machine-learning-515556ff72c5" target="_blank" rel="noopener">What is Online Machine Learning?</a></p>
<p>[2] <a href="https://ttic.uchicago.edu/~shai/papers/ShalevThesis07.pdf" target="_blank" rel="noopener">Online Learning: Theory, Algorithm and Applications</a> 一篇博士论文，介绍了关于分类器，标签排名算法(根据输入的相关度排名)</p>
<p>[3] <a href="https://arxiv.org/pdf/1802.02871.pdf" target="_blank" rel="noopener">Online Learning: A comprehensive survey</a> 一篇关于在线机器学习的综述，主要阐述了始终可获得完整反馈信息的在线监督学习算法，展现了优于传统机器学习算法只针对确定数据集进行训练的拓展性</p>
<h3 id="文献调研"><a href="#文献调研" class="headerlink" title="文献调研"></a>文献调研</h3><h4 id="1-众包中的机器学习问题研究（交大硕士论文-2014-主动学习）"><a href="#1-众包中的机器学习问题研究（交大硕士论文-2014-主动学习）" class="headerlink" title="1. 众包中的机器学习问题研究（交大硕士论文 2014 主动学习）"></a>1. 众包中的机器学习问题研究（交大硕士论文 2014 主动学习）</h4><p>这篇文章主要研究了机器学习利用众包数据辅助生成标签的几个问题</p>
<ul>
<li>标签质量控制问题<ul>
<li>用了一个概率模型来同时估计真实标签、标注者能力和数据实例难度</li>
</ul>
</li>
<li>标签矩阵补全问题<ul>
<li>类似电影打分机制，用概率矩阵分解来估计标签矩阵</li>
<li>通过已有的标签得到分类器来估计未知的标签，填充标签矩阵; 根据所有标签和权重(初始权重设置为平均的)来估计真实标签; 利用估计的真实标签和标签矩阵来估计标注者的能力。将以上步骤迭代进行</li>
</ul>
</li>
<li>主动学习（Active Learning）与众包学习相结合的问题<ul>
<li>主动学习是算法主动选择更有意义的未标注数据实例去送给人去标注</li>
</ul>
</li>
</ul>
<h4 id="2-Incremental-Relabeling-for-Active-Learning-with-Noisy-Crowdsourced-Annotations（2011-主动学习）"><a href="#2-Incremental-Relabeling-for-Active-Learning-with-Noisy-Crowdsourced-Annotations（2011-主动学习）" class="headerlink" title="2. Incremental Relabeling for Active Learning with Noisy Crowdsourced Annotations（2011 主动学习）"></a>2. Incremental Relabeling for Active Learning with Noisy Crowdsourced Annotations（2011 主动学习）</h4><p>主动学习可以从未标记的数据池中反复选择对分类器影响最大的那些样本。但是由于标签噪声的问题，将传统的主动学习算法直接应用于众包训练数据是有问题的。</p>
<p>这篇文章提出了一种新的主动学习方法，采用该方法可以在训练分类器模型时对噪声产生鲁棒性。文章数据采用了老年人活动识别领域中的应用，并使用AMT进行了模拟和真实实验，验证了所提出的方法。</p>
<h4 id="3-An-Online-Learning-Approach-to-Improving-the-Quality-of-Crowd-Sourcing-（密大论文-2017-在线学习）"><a href="#3-An-Online-Learning-Approach-to-Improving-the-Quality-of-Crowd-Sourcing-（密大论文-2017-在线学习）" class="headerlink" title="3. An Online Learning Approach to Improving the Quality of Crowd-Sourcing （密大论文 2017 在线学习）"></a>3. An Online Learning Approach to Improving the Quality of Crowd-Sourcing （密大论文 2017 在线学习）</h4><p>这篇文章主要解决了众包问题中用来训练分类器的标签选择问题。通过使用在线学习框架，随着任务的分配和执行，算法会估计标签质量，因此随着时间的流逝，算法会学会使用更有效的标签组合来实现任务。</p>
<p>在这项研究中，算法会分别计算工人质量和标签质量，最终我们将考虑多数表决规则以及加权多数表决规则，并根据给定的估计质量得出标签的各自最佳选择。</p>
<p>值得注意的是，文章提到了在在线解决方案中，有大量对主动学习进行的深入研究。例如引导工人提高贴标过程的效率，通过使用贝叶斯框架基于对标记结果观察来主动分配未标记的数据，以及使用使用概率模型来估计标记者的专业知识。文章的主要贡献概述如下。</p>
<ol>
<li>设计了一种在线学习算法，可以在没有真实事实信息但对假设总体人群质量有保证的情况下，估计在打标的质量，并表明它能够学习在简单和加权多数表决规则下获得最佳的标签设置。</li>
<li>为上述这种学习算法的成本提供了遗憾区间（regret bound）。始终使用最佳的标记器集。</li>
<li>展示了如何将我们的模型和结果扩展到标签质量取决于任务类型的情况，以及如何快速检测和滤除“spammer”（noise/噪声），以进一步提高众包质量。</li>
<li>使用AMT对模拟和真实数据集进行了验证。</li>
</ol>
<h4 id="4-CrowdControl-An-online-learning-approach-for-optimal-task-scheduling-in-a-dynamic-crowd-platform-（ICML-Workshop-Machine-Learning-Meets-Crowdsourcing-2013-在线学习）"><a href="#4-CrowdControl-An-online-learning-approach-for-optimal-task-scheduling-in-a-dynamic-crowd-platform-（ICML-Workshop-Machine-Learning-Meets-Crowdsourcing-2013-在线学习）" class="headerlink" title="4. CrowdControl: An online learning approach for optimal task scheduling in a dynamic crowd platform （ICML Workshop: Machine Learning Meets Crowdsourcing 2013 在线学习）"></a>4. CrowdControl: An online learning approach for optimal task scheduling in a dynamic crowd platform （ICML Workshop: Machine Learning Meets Crowdsourcing 2013 在线学习）</h4><p>这篇文章提供了一种新颖的在线方法，可实时控制和协调人群任务的执行，包括同时学习人群性能和基于学习进行优化。我们在此框架中设计和比较了几种算法，基于实际数据描述了工人表现的动态统计模型。文中对于工人质量的评估主要基于两个参数：平均完成时间和准确性的均方差比。 最终实验表明，通过自适应学习当前人群表现来调度任务的算法可以明显优于其他仅学习或不依赖过去数据的算法。</p>
<h4 id="5-Online-Learning-with-Self-Organizing-Maps-for-Anomaly-Detection-in-Crowd-Scenes-北大机器感知重点实验室-2010"><a href="#5-Online-Learning-with-Self-Organizing-Maps-for-Anomaly-Detection-in-Crowd-Scenes-北大机器感知重点实验室-2010" class="headerlink" title="5. Online Learning with Self-Organizing Maps for Anomaly Detection in Crowd Scenes (北大机器感知重点实验室 2010)"></a>5. Online Learning with Self-Organizing Maps for Anomaly Detection in Crowd Scenes (北大机器感知重点实验室 2010)</h4><h4 id="这篇文章主要是在线学习在人群中对行为进行标签的应用，非众包环境"><a href="#这篇文章主要是在线学习在人群中对行为进行标签的应用，非众包环境" class="headerlink" title="这篇文章主要是在线学习在人群中对行为进行标签的应用，非众包环境"></a><em>这篇文章主要是在线学习在人群中对行为进行标签的应用，非众包环境</em></h4><p>检测人群场景中的异常行为对于公共安全非常重要，并且已经引起越来越多的关注。以前的大多数方法都使用离线训练的模型来执行检测，无法处理不断变化的人群环境。在本文中，我们提出了一种新颖的无监督算法，可通过在线学习检测人群场景中的异常行为模式。</p>
<h4 id="6-On-Quality-Control-and-Machine-Learning-in-Crowdsourcing（无模型-仅论述）"><a href="#6-On-Quality-Control-and-Machine-Learning-in-Crowdsourcing（无模型-仅论述）" class="headerlink" title="6. On Quality Control and Machine Learning in Crowdsourcing（无模型 仅论述）"></a>6. On Quality Control and Machine Learning in Crowdsourcing（无模型 仅论述）</h4><p>这篇文章主要阐述了为机器学习提供大量数据的众包的各种质量控制问题，讨论了在众包过程中工人的影响和获取数据的研究者所应该注意的几个因素。</p>
<h4 id="7-Revolt-Collaborative-Crowdsourcing-for-Labeling-Machine-Learning-Datasets（它的主要概念和online-learning非常相似-2017）"><a href="#7-Revolt-Collaborative-Crowdsourcing-for-Labeling-Machine-Learning-Datasets（它的主要概念和online-learning非常相似-2017）" class="headerlink" title="7. Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets（它的主要概念和online learning非常相似 2017）"></a>7. Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets（它的主要概念和online learning非常相似 2017）</h4><p>本文主要介绍了一种用于改善标签质量的协作方法Revolt，可将想法从专家注释工作流引入基于人群的标签。 Revolt通过利用人群对模棱两可的物体的主要分歧来获取标签，从而消除了创建详细标签者的负担。Revolt可以生产高质量的标签，而又不需要标签准则。同时Revolt能够生产可重复使用的结构，而无需收集新数据，从而降低了前期成本。</p>
<p>文章一种新的众包标签收集方法，它可以使人群识别数据的主要分歧而产生标签，而不是尝试事先通过全面的准则明确定义目标概念，文中介绍了方法的实时和异步版本。</p>
<h3 id="思路总结"><a href="#思路总结" class="headerlink" title="思路总结"></a>思路总结</h3><p>科学问题是如何利用机器学习方法，辅助众包数据的产生。目前结合机器学习和众包领域的文章中，基本都采用了主动学习和在线学习两种算法，前者可以为分类器选择更好的未标注数据从而提高效率，后者则主要用于无人监督的环境下自行迭代训练，降低成本，提高质量。</p>
<p>利用标注数据，使用在线学习算法产生一个模型，使用这个模型对未标注数据进行打标，然后人工确认结果的正确性，将正确数据送回算法进行学习，最终产生一个众包的医疗病理数据集合。</p>
<p>我的想法：这是一个在有监督的环境下使用在线学习的辅助众包的算法，比起全众包获取数据的情况下，依然可以节省成本，获取更好的收益，可以和纯无人监督环境下训练的在线算法模型进行一些性能比较。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>众包中的机器学习问题研究</title>
    <url>/2020/02/18/%E4%BC%97%E5%8C%85%E4%B8%AD%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%E7%A0%94%E7%A9%B6/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>众包是一种分布式的问题解决模式。问题发布者将问题以公开招标的方式传播给未知的解决方案提供者群体。监督机器学习需要大量的人工标注数据。众包的发展为获取人工标注数据提供了一个新的方法。众包获取人工标注数据具有廉价、快速、规模大和方便控制等优点。因此得到了机器学习研究人员的广泛关注。众包标注数据虽然具有方便廉价的优点，但是也带来了问题。一般来说，传统的专家标注数据，数据标注都是比较准确的，质量问题不大。但是众包获得的数据，质量很有可能是有问题的。产生错误可能的原因包括众包工作者的态度、能力、对问题理解的差异、问题本身是比较难标注的等等。众包工作者可能给出错误的标签。既然现有的众包平台不能完全保证数据的质量，那么解决这种环境下的监督学习问题很有意义。现在很多研究人员提出用重复标注的方式产生冗余的标注数据，在这个数据上用机器学习算法来过滤噪声或者是估计更可靠的标注数据 。</p>
<a id="more"></a>

<p>本文研究关于众包的三个方面的问题。第一个是标签质量控制问题。考虑到标注者之间的能力差异、标注的样本数据之间的难易程度这两个因素，多数投票方法有很大的改进空间。本文提出鲁棒个人分类器算法，在个人分类器的基础上，能够从特征和标签数据中学习标注者的能力和分类器模型。第二个是标签矩阵补全问题。<br>在现实情况下，每个标注者只能标注部分数据样本，每个数据样本只得到部分标注者的标签。将众包标注者给出标签的过程类比看电影的用户给电影评分，我们提出用结合数据实例相似度的协同过滤算法来估计标注者对未标注数据的标签。最后再聚合真实标签和估计标签来得到更有效的算法模型。第三个是主动学习与众包学习结合的问题。我们将鲁棒个人分类器和主动学习有效结合，来解决众包得到标签过程中的任务路由问题，即如何选择最有信息价值的数据实例和为给定的数据选择最合适的标注者的问题。</p>
<h3 id="研究目标"><a href="#研究目标" class="headerlink" title="研究目标"></a>研究目标</h3><p>利用众包方式得到机器学习需要的标注数据时，不可避免的会带有噪声信息。我们提出利用机器学习算法来对众包标注数据进行质量控制。本文在众包得到的噪声数据上提取出高质量的标注数据并且学习出监督学习模型。通常众包标注数据是重复标注的，同一个样本会有多个标注者来进行标注。聚合多个标签最简单的方法是多数投票(Majority Voting，简称 MV)，即这个样本的标注数据取决于多数人的投票结果。多数投票是众包学习的一个常用的基准算法。</p>
<p>本文主要研究三个问题：</p>
<ol>
<li>标签质量控制问题<ol>
<li>一个概率模型来同时估计真实标签、标注者能力和数据实例难度。用 α 表示标注者能力，β 表示数据实例难度，Z 表示真实标签。</li>
</ol>
</li>
<li>标签矩阵补全问题<ol>
<li>类似电影打分机制，用概率矩阵分解来估计标签矩阵</li>
<li>通过已有的标签得到分类器来估计未知的标签，填充标签矩阵; 根据所有标签和权重(初始权重设置为平均的)来估计真实标签; 利用估计的真实标签和标签矩阵来估计标注者的能力。将以上步骤迭代进行。</li>
</ol>
</li>
<li>主动学习（Active Learning）与众包学习相结合的问题<ol>
<li>主动学习是从大量未标记的数据实例中挑选信息含量最高的实例，让人去标注，然后再去学习。主动学习可以减少数据标注的成本。这一点与众包学习的出发点很符合。众包学习中的主动学习也可以自然的扩展为挑选一个实例，再挑选一个标注者来标注。一般来说，主动学习最关键的地方是如何选择最有信息价值的数据实例。结合众包学习的主动学习，则既要挑选最有信息价值的数据实例，也要挑选标注准确率高的标注者。</li>
</ol>
</li>
</ol>
<h3 id="研究现状"><a href="#研究现状" class="headerlink" title="研究现状"></a>研究现状</h3><p>众包学习这个概念，意味着利用众包的方式得到标签，然后从带有噪声的标签中进行学习。与专家标注得到的标签相比，众包方式得到的标签往往是带有噪声的并且比较主观的。之前众包学习的工作 [12] 在他们的数据中发现存在部分标注者随机给出标签，证实了这一点。我们将不考虑特征数据而随机给出标签的标注者定义为<br>垃圾标注者(Spammer)。理论上讲，标签中的噪声除了来自这些垃圾标注者之外，还有部分噪声来自主观性的错误。由于标注者个人能力和经验以及对问题的理解，标注结果会出现一些错误。另外，很多时候问题本身的歧义性也使得标注数据很容易出错。这些因素会导致即使是好的标注者也会犯一些错误。</p>
<p>为了处理众包标签中的噪声问题，人们可以采用机制驱动和数据驱动的方法。机制驱动的方法由众包平台商决定，比如可以将事先已经知道标准答案的数据藏在所有问题中，然后根据用户在这些问题上的准确率来确定用户的可靠程度。这个方法是很有效的方法。缺点是制作带标准答案的数据比较麻烦。本文研究是数据驱动的方法，即我们拿到了带有噪声的数据，只利用这些数据来检测其中的垃圾标注者，并且建立准确的机器学习模型。一种广泛采用的方法是重复标注(Repeated Labeling)，即对于某个数据样本，我们会选多个标注者对之给出标签。最简单的方法是对每个数据样本进行投票，占多数的标签认为是最终的标签。这个方法被称为多数投票。这个方法虽然简单但是非常有效。这个方法的缺陷在于，平等的对待每个标注者。这样好的标注者和垃圾标注者在投票的时候得到了相同的权重，于是投票结果容易被垃圾标注干扰。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>V2ray/SS + VPS 部署教程</title>
    <url>/2020/02/14/V2ray-SS-VPS-%E9%83%A8%E7%BD%B2%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>由于疫情在家，看netflix，youtube的时间变多，因此对翻墙的速度产生了更高的需求，原有的ss实际速度常常只有10-20兆，于是产生了搭建vps，改用v2ray的想法。V2Ray相对于更Shadowsocks，更像一个全能选手，拥有更多可选择的协议 / 传输载体 (Socks、HTTP、TLS、TCP、mKCP、WebSocket )，还有强大的路由功能，不仅于此，它亦包含 Shadowsocks 组件，你只需要安装 V2Ray，你就可以使用所有的 V2Ray 相关的特性包括使用 Shadowsocks，由于 V2Ray 是使用 GO 语言所撰写的，天生的平台部署优势，下载即可使用。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/vps.png"/>

<a id="more"></a>

<h3 id="2020-5-11-Update-端口被封的解决方法"><a href="#2020-5-11-Update-端口被封的解决方法" class="headerlink" title="[2020/5/11 Update] 端口被封的解决方法"></a>[2020/5/11 Update] 端口被封的解决方法</h3><p>有些时候运营商可能会检测到流量不正常从而封掉ssh的某个端口，如何ssh依然可以连接可以在v2ray插件中中更改SS或者v2ray的端口设置，如果ssh也无法连接的话需要进入VPS后台，这里以KiwiVM为例。</p>
<ol>
<li><p>进入<code>Root shell - interactive</code>，默认登陆账号为root，密码如果遗忘可以在<code>Root shell - basic</code>中输入<code>echo &quot;root:password&quot; | chpasswd</code>将密码改为password。</p>
</li>
<li><p>连接到ssh之后，执行以下命令更改VPS的端口号</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>可以搜索Port并将后面的数字改成你自定义的端口号</p>
<ol start="3">
<li>重启ssh</li>
</ol>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ssh restart ## debian</span><br><span class="line">service ssh restart ## ubuntu</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>验证端口是否被成功更改</li>
</ol>
<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">netstat -nlpt <span class="string">| grep ssh</span></span><br></pre></td></tr></table></figure>

<p>大功告成！</p>
<h3 id="简单流程"><a href="#简单流程" class="headerlink" title="简单流程"></a>简单流程</h3><ol>
<li><p>购买一个 VPS</p>
<blockquote>
<p>想要搭建 V2Ray，就必须要拥有一台 VPS）</p>
</blockquote>
</li>
<li><p>获取 VPS 信息</p>
<blockquote>
<p> 我们必须要知道 VPS IP 地址，root 用户密码，SSH 端口</p>
</blockquote>
</li>
<li><p>仅限Windows: 安装 Xshell</p>
<blockquote>
<p>Xshell 是一个 SSH 客户端，Mac 用户直接在终端登入ssh root@ip即可</p>
</blockquote>
</li>
<li><p>登录 VPS</p>
<blockquote>
<p>使用 Xshell 配置 VPS SSH 信息，然后登录</p>
</blockquote>
</li>
<li><p>安装 V2Ray</p>
<blockquote>
<p>安装过程你可以随意选择你喜欢的传输协议，此时也可顺便配置 Shadowsocks</p>
</blockquote>
</li>
<li><p>V2Ray 高级玩法</p>
<blockquote>
<p>配置 WebSocket + TLS ， HTTP/2 ， mKCP 等</p>
</blockquote>
</li>
</ol>
<h3 id="详细教程"><a href="#详细教程" class="headerlink" title="详细教程"></a>详细教程</h3><p>想要搭建 V2Ray， 拥有一个 VPS 是必需的。现在市场上VPS供应商泛滥，可以按照个人喜好选择。较为知名的有搬瓦工（Bandwagon Host），其CN2 GIA线路对中国用户非常友好，不过截止目前该线路所有服务器均已售罄。 这里我个人的建议是选择一个相对小众的供应商，这样不至于大量中国用户涌入导致高峰期线路拥堵，影响速度。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/vpsplan.png"/>

<p>在订单成功之后，运营商会为你提供root密码，ip地址等信息，作为Mac用户，只需要简单在终端中输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh root@ip address</span><br></pre></td></tr></table></figure>

<p>然后输入密码，就能登陆到远程服务器了。退出服务器只需要<code>control + D</code>即可。</p>
<p>这里我们的VPS系统使用了debian-9-x86_64，进入虚拟环境后，首先安装curl（以下命令也适用于ubuntu）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">apt-get update -y &amp;&amp; apt-get install curl -y</span><br></pre></td></tr></table></figure>

<p>或者，假如你是CentOS用户</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum update -y &amp;&amp; yum install curl -y</span><br></pre></td></tr></table></figure>

<p>安装完成之后，使用V2Ray安装脚本</p>
<figure class="highlight lisp"><table><tr><td class="code"><pre><span class="line">bash &lt;(<span class="name">curl</span> -s -L https<span class="symbol">://git</span>.io/v2ray.sh)</span><br></pre></td></tr></table></figure>

<p>首次进入<code>v2ray</code>后，只要按照提示一路设置即可，如果你想使用 Shadowsocks ，那么现在你可以自己配置一下Shadowsocks 参数了，之后我们可以随时调用<code>v2ray</code>查看或修改我们的配置。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/v2ray.png"/>

<h3 id="快速管理"><a href="#快速管理" class="headerlink" title="快速管理"></a>快速管理</h3><p><code>v2ray info</code> 查看 V2Ray 配置信息<br><code>v2ray config</code> 修改 V2Ray 配置<br><code>v2ray link</code> 生成 V2Ray 配置文件链接<br><code>v2ray infolink</code> 生成 V2Ray 配置信息链接<br><code>v2ray qr</code> 生成 V2Ray 配置二维码链接<br><code>v2ray ss</code> 修改 Shadowsocks 配置<br><code>v2ray ssinfo</code> 查看 Shadowsocks 配置信息<br><code>v2ray ssqr</code> 生成 Shadowsocks 配置二维码链接<br><code>v2ray status</code> 查看 V2Ray 运行状态<br><code>v2ray start</code> 启动 V2Ray<br><code>v2ray stop</code> 停止 V2Ray<br><code>v2ray restart</code> 重启 V2Ray<br><code>v2ray log</code> 查看 V2Ray 运行日志<br><code>v2ray update</code> 更新 V2Ray<br><code>v2ray update.sh</code> 更新 V2Ray 管理脚本<br><code>v2ray uninstall</code> 卸载 V2Ray</p>
<h3 id="优化-V2Ray"><a href="#优化-V2Ray" class="headerlink" title="优化 V2Ray"></a>优化 V2Ray</h3><p>由于安装的脚本在 Debian9 系统会自动开启 BBR 优化加速了，所以不需要再安装 BBR 优化了。<br>如果你还是觉得网络比较慢的话，你可以尝试使用含有 mKCP 的传输协议，这个 mKCP 简单来说就像 Kcptun 一样加速，并且还能进行伪装 (可选)，但是由于 mKCP 是使用 UDP 协议的，也许运营商会限速得更加厉害，网络变得更加慢。但不管怎么样，你都可以随时尝试一下。<br>服务器输入 <code>v2ray config</code> 回车，然后选择 修改 V2Ray 传输协议，再接着选择 mKCP 相关的传输协议即可<br>如果你是使用其他商家的 VPS 并且是按照此教程流程来安装 V2Ray 的话，那么你可以输入 <code>v2ray bbr</code> 回车，然后选择安装 BBR 或者 锐速 来优化 V2Ray。</p>
<blockquote>
<p>如果你是使用国际大厂的 VPS，并且是按照此教程流程来安装 V2Ray 的话，请自行在安全组 (防火墙) 开放端口和 UDP 协议 (如果你要使用含有 mKCP 的传输协议) </p>
</blockquote>
<h3 id="WebSocket-TLS"><a href="#WebSocket-TLS" class="headerlink" title="WebSocket + TLS"></a>WebSocket + TLS</h3><p>实现 WebSocket + TLS 的前提是要拥有一个能正常解析的域名 (并且知道怎么解析域名)。<br>服务器输入 <code>v2ray config</code> 回车，然后选择 修改 V2Ray 传输协议，再选择 WebSocket + TLS，即是输入 4，接着输入你的域名。<br>使用WS + TLS 并不是 V2Ray 的神级配置，该墙还是会墙，比如它会有断流的问题。</p>
<h3 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP/2"></a>HTTP/2</h3><p>实现 HTTP/2 (h2) 也很简单，和 WebSocket + TLS 一样，也就是只要一个域名就够。<br>服务器输入 <code>v2ray config</code> 回车，然后选择 修改 V2Ray 传输协议，再选择 HTTP/2，即是输入 16，然后看上面的 WebSocket + TLS 的相关。<br>备注一下，HTTP/2 相比 WS + TLS (WebSocket + TLS) ，在浏览网页时有一些优势，不过速度总体是差不多的。</p>
]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>一篇关于众包的简要介绍和一些数据集整理</title>
    <url>/2020/02/09/2020-02-06-Machine-Learning-Crowdsourcing-Concepts/</url>
    <content><![CDATA[<h3 id="众包是什么？"><a href="#众包是什么？" class="headerlink" title="众包是什么？"></a>众包是什么？</h3><p>众包，简单来说就是在当前互联网蓬勃发展的大环境下一种新兴的利用了分布式计算的商业模式。曾有人预言说，计算机很长一段时间无法取代人类，计算机和人类会各自负责自己擅长的部分。现在的众包任务就是如此，它指那些主要需求人类智慧解决的任务，这些任务往往工作量不大，或是可以拆分成许多小任务。</p>
<p>众包通常具有三个基本要素：提供众包平台的供应商，众包任务发布者，参与众包任务的工人。</p>
<p>当前主流的众包系统问题主要有：众包任务设计，时空众包任务分配，工人的质量评估和选择，结果聚合。</p>
<h3 id="数据集及其研究问题"><a href="#数据集及其研究问题" class="headerlink" title="数据集及其研究问题"></a>数据集及其研究问题</h3><h4 id="Foursquare-Dataset"><a href="#Foursquare-Dataset" class="headerlink" title="Foursquare Dataset"></a>Foursquare Dataset</h4><p>地址：<a href="https://sites.google.com/site/yangdingqi/home/foursquare-dataset" target="_blank" rel="noopener">https://sites.google.com/site/yangdingqi/home/foursquare-dataset</a></p>
<p>介绍：Foursquare是一家基于用户地理位置信息（<a href="https://baike.baidu.com/item/LBS/1742" target="_blank" rel="noopener">LBS</a>）的手机服务网站，鼓励手机用户同他人分享自己当前所在地理位置等信息。这个数据集记录了从2011年10月24日至2012年2月20日关于纽约市餐厅的数据。数据集中有3112个用户信息和3298个位置信息，还有27149个“check-in”和10377个用户的“tips”。</p>
<p>相关研究：通过用户的地理信息研究其对于特定地点的偏好（incentives），改进空间众包任务的推荐系统。</p>
<ul>
<li>Dingqi Yang, Daqing Zhang, Zhiyong Yu and Zhiwen Yu, Fine-Grained Preference-Aware Location Search Leveraging Crowdsourced Digital Footprints from LBSNs. In Proceeding of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2013), September 8-12, 2013, in Zurich, Switzerland. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww-public.it-sudparis.eu%2F~zhang_da%2Fpub%2FUbiComp_2013_Yang.pdf&sa=D&sntz=1&usg=AFQjCNErnJGR0J3FJH4lkJdA9oRjkhsglQ" target="_blank" rel="noopener">[PDF]</a></li>
<li>Dingqi Yang, Daqing Zhang, Zhiyong Yu and Zhu Wang, A Sentiment-enhanced Personalized Location Recommendation System. In Proceeding of the 24th ACM Conference on Hypertext and Social Media (HT 2013), 1-3 May, 2013, Paris, France. <a href="http://www.google.com/url?q=http%3A%2F%2Fwww-public.it-sudparis.eu%2F~zhang_da%2Fpub%2FHT2013_Dingqi%20YANG.pdf&sa=D&sntz=1&usg=AFQjCNE-KO-83K11ShSmi7XaEeGaxQf0mw" target="_blank" rel="noopener">[PDF]</a></li>
</ul>
<h4 id="CMCC-Dataset"><a href="#CMCC-Dataset" class="headerlink" title="CMCC Dataset"></a>CMCC Dataset</h4><p>地址：<a href="http://datatech.zjdex.com/data/" target="_blank" rel="noopener">http://datatech.zjdex.com/data/</a> （暂时无法访问）</p>
<p>介绍：这个数据集记录了从2017年5月28日到2017年6月28日浙江省手机用户的移动信息，可以获取到的信息有出入某地点（经纬度）的具体时刻（精确到分钟）。</p>
<p>相关研究：移动众包（使用移动设备进行众包，利用高移动性可以解决那些地理上分散的任务），为移动众包分配任务的问题</p>
<ul>
<li>Z. Feng, Y. Zhu, Q. Zhang, L. M. Ni and A. V. Vasilakos, “TRAC: Truthful auction for location-aware collaborative sensing in mobile crowdsourcing,” <em>IEEE INFOCOM 2014 - IEEE Conference on Computer Communications</em>, Toronto, ON, 2014, pp. 1231-1239. [<a href="https://ieeexplore.ieee.org/abstract/document/6848055/" target="_blank" rel="noopener">pdf</a>]</li>
</ul>
<h4 id="D4D-Dataset"><a href="#D4D-Dataset" class="headerlink" title="D4D Dataset"></a>D4D Dataset</h4><p>“D4D” = “Data for Development”, 这也是一个记录了手机的地理位置信息的数据集。其中包含两种数据类型。一种包含有关手机信号的信息，包括信号ID，纬度和经度。另一个包含在美国橘县象牙湾的50,000个用户的电话记录。</p>
<p>相关研究：众包任务分配问题</p>
<ul>
<li>Zhang, D., Xiong, H., Wang, L., &amp; Chen, G. (2014, September). CrowdRecruiter: selecting participants for piggyback crowdsensing under probabilistic coverage constraint. In Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing (pp. 703-714). ACM.</li>
<li>Liu, Y., Guo, B., Wang, Y., Wu, W., Yu, Z., &amp; Zhang, D. (2016, September). TaskMe: multi-task allocation in mobile crowd sensing. In Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing (pp. 403- 414). ACM.</li>
<li>Xiong, H., Zhang, D., Chen, G., Wang, L., Gauthier, V., &amp; Barnes, L. E. (2016). iCrowd: Near-optimal task allocation for piggyback crowdsensing. IEEE Transactions on Mobile Computing, 15(8), 2010-2022.</li>
<li>Wang, J., Wang, Y., Zhang, D., Xiong, H., Wang, L., &amp; Sumi, H., et al. (2016). Fine-grained multi-task allocation for participatory sensing with a shared budget. Internet of Things Journal (in press). </li>
<li>Wang, J., Wang, Y., Zhang, D., Wang, F., He, Y., &amp; Ma, L. PSAllocator: Multi-Task Allocation for Participatory Sensing with Sensing Capability Constraints. The, ACM Conference on Computer- Supported Cooperative Work and Social Computing (CSCW 2017).  </li>
</ul>
<h4 id="Stanford-Large-Network-Dataset-Collection-（Brightkite-and-Gowalla）"><a href="#Stanford-Large-Network-Dataset-Collection-（Brightkite-and-Gowalla）" class="headerlink" title="Stanford Large Network Dataset Collection （Brightkite and Gowalla）"></a>Stanford Large Network Dataset Collection （Brightkite and Gowalla）</h4><p>Source: J. Leskovec and A. Krevl, “Snap datasets: Stanford large network dataset collection,” Jun. 2014.</p>
<p>介绍：该数据集记录了大量社交网络信息，包括社区，娱乐，食品，夜生活，户外活动，购物和旅行，以及其子类别。该数据集还收集了用户的个人资料，社交关系和酒店入住信息。</p>
<p>相关研究：通过众包数据在基于地点产生的社交网络中探索影响力（传播）最大化问题，众包工人的隐私问题</p>
<ul>
<li>Using Crowdsourced Data in Location-based Social Networks to Explore Influence Maximization </li>
<li>(A Book) Trends and Applications in Knowledge dISCOVERY AND Data Mining</li>
</ul>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title>Accurate inference of crowdsourcing properties when using efficient allocation strategies</title>
    <url>/2020/02/08/2020-02-08-accurate/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>常见的分配策略通过减少准确完成单个任务所需的工作来提高众包效率，但是这些算法通过优先将工人分配给简单的任务而引入了偏差，导致完成的任务集不再代表所有任务。这种偏见挑战着对问题范围广泛的属性（例如典型的任务难度）或人群属性（例如工人完成时间）的推论，这些重要信息超出了人群响应本身。在这里，我们研究使用分配算法提高人群效率时有关问题属性的推论。我们介绍了决策显式概率采样（DEPS），一种在考虑分配策略引入的潜在偏差的同时执行问题属性推断的方法。对真实和综合众包数据进行的实验表明，DEPS优于基准推理方法，同时仍在利用分配方法的效率提升。使用非代表性数据时，可以对一般属性进行准确的推断，从而使众包发布者可以从给定的众包数据集中提取更多知识。</p>
<a id="more"></a>

<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>在本文中，我们描述了一个众包问题的模型固定预算，讨论众包问题的性质，我们引入并详细介绍了分配算法以提高众包效率，说明了使用有效分配策略时属性推断的挑战。我们还介绍了决策显式概率采样（DEPS），这是一种将分配算法的结果集成到属性推断中的策略。最后，我们进行了在实际和综合众包数据上使用DEPS进行的实验。</p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>我们研究了三个众包数据集，这些数据都不是使用有效的分配算法生成的。</p>
<h4 id="RTE识别文本蕴含（RTE）数据集"><a href="#RTE识别文本蕴含（RTE）数据集" class="headerlink" title="RTE识别文本蕴含（RTE）数据集"></a>RTE识别文本蕴含（RTE）数据集</h4><p>每个任务都是成对的文本片段，每对片段都具有一定的定向关系，将他们展示给Amazon Mechanical Turk工人，同时记录工人回答是否陈述涉及另一个。整个数据集由 800个可选任务组成，每个任务都有10个工人参与，因此总共记录了8000个工人的回答。</p>
<p>####识别蓝鸟数据集。</p>
<p>每个任务都是一张蓝鸟的照片，然后询问工人照片中是否包含蓝鸟。 数据集中共有108个可选任务，每个任务有39个工人参与，因此，总共有4212个答案。</p>
<h4 id="识别页面相关性数据集"><a href="#识别页面相关性数据集" class="headerlink" title="识别页面相关性数据集"></a>识别页面相关性数据集</h4><p>每个任务都会显示一个网页和一个给定的主题，要求工人确定该网页是否与给定的主题相关。该数据集包含2275个任务，每个任务的需求工人数为1到10，实际平均工人参与为6.04。总共有13,749个工人的回答。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>data collection</tag>
      </tags>
  </entry>
  <entry>
    <title>A Crowdsourcing Worker Quality Evaluation Algorithm on MapReduce for Big Data Applications</title>
    <url>/2020/02/08/2020-02-08-evaluation/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>众包是在互联网蓬勃发展的背景下一种新兴的分布式计算和商业模式。随着众包系统的发展，众包方，承包商和任务的数据量迅速增长。基于大数据分析技术的工人质量评估已成为一项严峻的挑战。本文首先提出了一种通用的工人质量评估算法，该算法可应用于任何关键任务，例如标记，匹配，过滤，分类和许多其他新兴应用，而不会浪费资源。其次，我们使用MapReduce并行编程模型在Hadoop平台上实现评估算法。最后，为了有效地验证算法在各种大数据场景下的准确性和有效性，我们进行了一系列实验。实验结果表明，该算法是准确有效的。它具有较高的计算性能和水平可伸缩性。它适用于大数据环境中的大规模工人质量评估。</p>
<a id="more"></a>

<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>众包是一种分布式解决问题的生产力模型，在这种分布式计算的模型中，企业通过互联网分配任务，并招募更多合适的工人来解决一些问题。如今，越来越多的企业和企业开始使用众包模型。对于企业而言，众包模式可以降低生产成本，并提升其劳动力缺口和创造力。众包模式面向公众，每个互联网用户都可以选择参与他们感兴趣的众包任务，从而为企业提供解决方案。但是，对于一项任务，可能会涉及大量的工人并提供解决方案。当众筹者面对如此众多的解决方案时，他们会感到困惑，他们很难做出最终选择。而且，并非每个人都有资格因其背景和个人素质的不同而服务于企业。众包平台甚至可能有恶意工作者。因此，工人质量控制已逐渐成为众包模式的重要挑战。从大量的工人数据中挖掘有关工人自我素质的信息，为众包提供一些参考非常重要。</p>
<p>本文将主要集中在工人的质量控制问题上，工人素质评估将帮助企业招聘，可为他们提供高质量解决方案的高素质工人。这对于众包平台的任务质量和环境都具有重要意义。由于具有大规模的众包平台，众包者几乎随时都可以发布任务。另外，大量的工人参与这些任务。因此，众包平台每时每刻都会生成大量数据，包括众包任务，员工行为和任务解决方案。大量数据对众包平台的计算性能提出了新的要求。大数据技术的使用对这些海量数据进行特殊处理是众包平台需要考虑的关键问题。</p>
<p>为了在众包平台上准确评估工人的素质，我们首先提出了一种通用的工人素质评估算法，该算法可对多个工人和多个问题类型进行工人质量评估，而无需预先制定答案。该算法具有更强的可扩展性和实用性。其次，我们建议使用MapReduce编程模型来实现大规模并行计算以提高工作人员的素质，并在Hadoop平台中实施所提出的算法。最后，我们进行了一系列实验，以分析和评估工人质量评估算法的性能。实验结果表明，该算法是有效的，并且具有较高的性能。它可以满足在大数据环境的众包平台中对大型工人进行并行评估的需求。</p>
<h3 id="工人质量评估算法"><a href="#工人质量评估算法" class="headerlink" title="工人质量评估算法"></a>工人质量评估算法</h3><p>我们首先提出一种面向选择的工人质量评估算法，该算法称为M-1算法。基于M-1算法，我们进一步提出了多员工评估方案和M-X算法，一种多选评估方案。</p>
<h4 id="M-1算法"><a href="#M-1算法" class="headerlink" title="M-1算法"></a>M-1算法</h4><p>M-1算法的思想描述如下：假设所有提供的问题属于同一类型（单选），并且没有预先制定的答案。让三个工人w1， w2，w3同时回答这些问题。问题的数量为N。然后，我们将根据他们的回答相似性来计算每个工人回答问题的准确性。</p>
<p>众包平台中有各种各样的任务。不同的任务具有不同的M值并具有各自的特征。与历史任务相比，新发布的任务可能具有完全不同的模式。而且，所有新发布的任务都没有预先开发的答案，并且选项的顺序是不可预测的。因此，很难预测哪个选项更可能是正确的答案以及工人对不同选项的偏好。为了为众包工人质量评估提供一个通用的解决方案，我们假设每个工人拥有为一个问题选择每个错误选项的相同概率。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/eva-al11.png"/>

<h4 id="基于M-1的多人评价算法"><a href="#基于M-1的多人评价算法" class="headerlink" title="基于M-1的多人评价算法"></a>基于M-1的多人评价算法</h4><p>在M-1算法中，我们解决了三工质量评估的问题。但是，在实际的众包环境中，可能有多个工人同时参与同一任务。如何评估多功能工人的质量是一个尚待解决的实际问题。因此，我们提出了一种基于M-1算法的多员工评价方案，该方案采用了滑动窗口的思想。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/eva-al2.png"/>

<h4 id="M-X-算法"><a href="#M-X-算法" class="headerlink" title="M-X 算法"></a>M-X 算法</h4><p>与单选相比，选择题是更一般的问题类型。更确切地说，单选是多项选择的一种特殊形式。例如，对于某些标签问题，我们只需要为每个对象分配一个标签。但是，在大多数情况下，我们需要为每个对象分配多个标签。因此，M-X算法专注于多项选择题。对于多项选择，不同工人对同一问题的答案往往会有很大差异。因此，当我们解决多项选择题时，我们几乎无法使用M-1算法直接评估工人的素质。因此，基于M-1算法，我们提出了一种针对问题的多项选择的工人质量评估算法，称为M-X算法。</p>
<p>M-X算法的思想如下。首先，我们根据一个问题的M值将其划分为M个子问题，M值代表每个多项选择问题的选择数量。每个选项被视为具有两个选项的单选问题，每个具有M个选项的多项选择题都将转换为M个单选问题。其次，对于每个选项维度，我们将其作为子任务处理，其中包含N个单选问题。这样，每个任务被划分为M个子任务。然后，我们使用算法2分别计算工人在每个选项维度上的准确性。最后，对于一个工人，我们收集所有选项维度的准确性，以计算工人对多项选择题的综合准确性值。对于每个多项选择题，答案都是正确的必要和充分条件是工人为多项选择题选择所有正确的选择。因此，工人的最终准确性是从每个选项的尺寸获得的所有准确性值的乘积。</p>
<img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/eva-al3.png"/>

<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>在本节的实验之一中，我们招募10名工人参与同一任务。然后，我们使用提出的工人质量评估算法来计算每个工人的准确性，以初步验证我们算法的有效性。为了在各种大数据场景中更有效地验证该算法的准确性和有效性，我们在本节中进一步进行了一系列仿真实验，以分析和评估工人质量评估算法的性能。实验是在Hadoop平台上使用模拟数据进行的。对于一个任务，我们首先根据任务中的问题类型（布尔值，单选，多项选择等）随机生成问题的答案。然后，我们随机生成不同级别的工人。工人的水平主要取决于准确性。精度在0到1之间。最后，我们根据生成的工人精度来生成每个工人对每个问题的响应。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>在本文中，我们首先提出了一种通用的工人质量评估算法，该算法可用于没有预先制定的答案的任何关键的众包任务。然后，为了满足在大数据环境中对多个工作人员进行并行评估的需求，我们使用Map-Reduce编程模型在Hadoop平台中实现了该算法。实验结果表明，该算法准确，在大数据环境下具有较高的效率和性能。<br>在未来的研究中，我们将进一步考虑影响员工素质的其他因素，例如回答时间和任务难度。这些因素将有助于实现对工人素质的全面评估，以适应大数据环境下的众包模式在不同情况下的工人素质评估问题。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>big data</tag>
        <tag>quality control</tag>
      </tags>
  </entry>
  <entry>
    <title>A trust‐aware task allocation method using deep q‐learning for uncertain mobile crowdsourcing</title>
    <url>/2020/02/07/2020-02-08-trust-aware/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>移动众包已经成为一种很有前途的协作范例，每个任务都需要在指定空间位置附近找到工作人员。考虑到参与者所需求的移动设备的隐私问题，信任将是有效协作的重要因素。移动众包的首要问题是将值得信赖的移动工作人员分配给附近的任务以进行协作。对于不确定的移动众包系统而言，大规模在线空间任务分配极具挑战性。这种不确定性可能会误导任务分配，从而导致性能下降。此外，现实世界中众包的大规模性质对不确定环境中的空间任务分配提出了相当大的挑战。为了解决上述挑战，我们需要制定移动众包任务分配的优化问题，以最大程度地提高工人的信任度并最小化移动距离成本。其次，针对不确定的众包场景，我们提出了一种基于马尔可夫决策过程的移动众包模型（MCMDP），以说明动态的信任感知任务分配问题。第三，为了稳定地解决大规模MCMDP问题，本研究提出了一种改进的基于深度-Q-学习的信任感知任务分配算法，该算法结合了信任感知任务分配和深度Q学习作为对不确定的移动众包系统的改进。最后，实验结果表明改进的DQL-TTA算法可以在许多训练迭代中稳定收敛。与参考算法相比，我们提出的算法在实验数据集上获得了有效的解决方案。</p>
<a id="more"></a>]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>collaborative computing</tag>
        <tag>mobile crowdsourcing</tag>
        <tag>task allocation</tag>
      </tags>
  </entry>
  <entry>
    <title>Efficient budget allocation and Task Assignment in Crowdsourcing</title>
    <url>/2020/02/07/2020-02-07-Efficient-budget/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文探讨了如何就一个固定的预算提高在众包平台雇佣工人完成任务的效率，影响效率的不确定性有工人的工作时间，技能水平和完成任务的时间。已有的文章采用任务的顺序分配，往往假定一个任务只分配给一个工人，而本文的问题则设定在一个众包平台下的动态工人池中。文中介绍了一个新定义的数学模型，进行了多步实验证明了其比原有的顺序分配花费更少的时间且具备更优的策略。文章的主要贡献有</p>
<p>（1）提出了在动态工人池下众包的预算分配和任务分配问题。 </p>
<p>（2）提供有效的数学模型和算法科学地解决问题。</p>
<p>（3）提供实验证据以支持有效性的算法。</p>
<a id="more"></a>

<h3 id="数学模型"><a href="#数学模型" class="headerlink" title="数学模型"></a>数学模型</h3><p>文中定义了一系列标签${1,2,…,I}$用来标注每个任务，第i个任务的难度标注为$\alpha_i$，t时间的工人数量为$N_t$, t时间的任务池为总任务池的子集$I_t$，最终每个任务的标签由所有标签的众数决定。由于是一系列的标签决策问题，我们使用马可夫决策过程(MDP)。</p>
<p>马可夫决策过程是一个四元的元组$M=(S,A,P,R)$， 其中S是所有状态集合，A是所有行为的集合，P是状态量，R是奖励方程。每个时间点状态量都会改变，我们用额外的参量去定义，同时更新剩下的量，这里考虑使用动态规划。</p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>对于预算分配问题，一种算法会每次随机取出一部分任务，直到预算耗尽，这种算法叫RAND。另一种算法EQ则将总预算分配到所有任务上，这种算法在任务难度相同时非常合适。</p>
<p>文章提出了一个新的加权幂的平均，用来估计每个任务所占理想预算的权重，因此我们提出算法PM(p)，其中p是我们人工设定的参数，使得label上获取的reward最大。</p>
<p><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/alg1.png" alt="Algorithm 1: PM(p)"></p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>文章提供了三个实验结果，一个是设置p为1后比较RAND,EQ和HM的精确度，第二个是对不同算法进行调参，查看结果对比，最后一个是考虑的工人技能影响的不同算法比较。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>task assignment</tag>
      </tags>
  </entry>
  <entry>
    <title>Efficient Learning-Based Recommendation Algorithms for Top-N Tasks and Top-N Workers in Large-Scale Crowdsourcing Systems</title>
    <url>/2020/02/06/2020-02-06-Efficient%20Learning-Based%20Recommendation%20Algorithms%20for%20Top-N%20Tasks%20and%20Top-N%20Workers%20in%20Large-Scale-Crowdsourcing-Systems%20copy/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在传统推荐系统中，尚不存在贴合众包的时间短，任务重，工人匹配度要求高的推荐方案。在本文中，我们提出了一个含有两层的数据表示方案（新定义了两种评分：工人-类别适合性评分和工人-任务吸引力评分），以支持个性化的任务和工人建议。本文还扩展了两种优化方法，即最小均方差（LMS）和多反馈贝叶斯个性化排序算法(BPR)，以更好地适应众包系统中任务/工人推荐的特征。本文把提出的四种方法集成了两个流行的学习模型：矩阵分解和kNN，得出了适用于众包系统的两个top-N推荐算法：（1）Top-N-任务推荐算法，用于发现给定工作人员的前N个最适合的任务（2）Top-N -Workers推荐算法，用于确定任务请求者的前N名最佳工人。</p>
<a id="more"></a>

<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><ul>
<li><p>文章定义的推荐方法首先要给任务和工人进行分类，从而获得最佳任务排名和最佳工人排名算法，TNT和TNW。最佳任务排名既要考虑最适合工人的任务也要考虑对公认最有吸引力的任务，最佳工人排名则有三步，首先拓展任务分类找到近似任务，从这些任务里找到有资格的工人，再从这些工人里筛选出最有可能接受任务的工人。</p>
</li>
<li><p>文章定义了两种分数：第一个是工人的任务适应分，第二个是任务喜好分。</p>
</li>
<li><p>本文运用了两种优化方法：最小均方差和贝叶斯个性化排序方法，且可以在矩阵矩阵分解或knn模型中训练。</p>
</li>
</ul>
<h3 id="方法论和数据表达"><a href="#方法论和数据表达" class="headerlink" title="方法论和数据表达"></a>方法论和数据表达</h3><h4 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h4><p>这一部分文章主要表现了一些传统的电商推荐系统算法和众包的推荐系统算法的区别</p>
<ol>
<li>众包任务和产品的生命周期：前者是动态的，后者是静态的，我们需要更个性化的推荐内容</li>
<li>众包工人的选择和产品买者的选择：前者受限于技能水平，后者基本无限制，所以我们在算法中定义了分类</li>
<li>众包任务质量和产品质量：工人质量直接影响任务完成质量，产品质量和工人无关，本文不考虑高水平的工人因为赶时间等因素完成低质量任务的情况</li>
<li>众包任务的独特性和产品的单一性：众包任务因为其特殊的活动特性（被不同的工人完成），注定了他的独特性，而产品在流水线上生产，则需要唯一性。因此我们的推荐系统注定不能用单一的标准去衡量工人，不然会导致众包任务丧失其独特性。</li>
<li>双向性推荐系统：我们采用了TNT和TNW两种评分算法，使得推荐过程变成双向选择。</li>
</ol>
<h4 id="数据表达"><a href="#数据表达" class="headerlink" title="数据表达"></a>数据表达</h4><p>如前文所提到的，本文新定义了两种分数：工人的任务适应分和工人的任务喜好分。文章又新定义了几个参数完善了整个模型，具体数学表达及定义可以参见原文。</p>
<p>由于工人具有定义的多个属性，所以使用了矩阵表达，在模型的学习上使用了矩阵分解和k近邻算法来预测其适用性/喜好分数，同样，具体数学表达及定义可以参见原文。</p>
<p>由于前面定义的方法没有考虑工人对不喜欢任务的权重，这里采取了多反馈贝叶斯个性化排序算法(BPR)来优化前面得到的几个分数。之后的算法部分主要阐述了文章定义的TNT和TNW的具体实现，且考虑了多种标准，不同阶段下的不同情况。</p>
<h3 id="结果评估"><a href="#结果评估" class="headerlink" title="结果评估"></a>结果评估</h3><p>这部分主要是说明调参的结果，给出了不同标准下两个算法的参数设置和实验结果。每个算法都有和其他算法的精确度比较，还计算了算法的复杂度。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>machine learning</tag>
        <tag>task recommendation</tag>
        <tag>ranking algorithms</tag>
      </tags>
  </entry>
  <entry>
    <title>Crowdsourced Continuous Improvement of Medical Speech Recognition</title>
    <url>/2020/02/05/Medical%20Speech%20Recognition/</url>
    <content><![CDATA[<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文描述了一种使用涉及多组工人的多步周期来不断提高大型医疗自动语音识别器（ASR）的准确性的方法。本文将解决医学领域的独特挑战，并讨论如何结合自动创建和众包的输入数据来完善ASR语言模型。改进周期有助于将原始系统的单词错误率从34.1％降低到10.4％，接近了接受医学转录训练的人类转录员的准确性。</p>
<p><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/Production%20Cycle.png" alt="Figure 1: Production Cycle and Continuous Improvement Cycle."></p>
<a id="more"></a>

<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>现存语音翻译系统的问题： 缺乏医学专业词库</p>
<p>解决方法：创建了一个系统可以录下医生的音频，然后创造一份面向患者的报告。这个系统有两个stages</p>
<ol>
<li>ASR - 生成医生口述的书面稿</li>
<li>Auto formatting - 自动完成报告</li>
</ol>
<p>这里需要注意的是医生口述中很多口语化的语句（比如口误或重复）应该在被翻译成书面稿时跳过，为了实现这个要求，该文使用签署保密协议的private crowd进行翻译，并称之为基于众包的持续改进循环系统（Continuous Improvement Cycle）。</p>
<p>###基于众包的持续改进循环系统</p>
<ul>
<li>部署两个独立的听写者组，<strong>Crowd T</strong> 和 <strong>Crowd R</strong>，第一组用于完善并改正ASR对于音频的预测，同时保留所有口语化的语句。第二组用来生成最终的完成版报告，去除了一些口语化语句，增强翻译内容的可读性。这两个组将会融入图一所示的Production Cycle，流程分为四步：</li>
</ul>
<ol>
<li><p>用户在客户端上上传需要翻译的音频</p>
</li>
<li><p>音频和ASR翻译的假设被送往Crowd T进行人工修改（ASR的识别力比受过专业训练的人工更强）。</p>
</li>
<li><p>人工润色过的稿件被送往Auto formatting进行进一步修改，部分要求如下</p>
</li>
</ol>
<blockquote>
<p>1) post-processing tokens and phrases (e.g., “three point five over five period” to “3.5/5.”)</p>
<p>2) removing unneeded sen- tences and inserting standard statements (e.g., closing statement and headers)</p>
<p>3) restructuring content into ti- tles, sentences and paragraphs</p>
<p>4) extracting standard report fields such as date of service and patient name. </p>
</blockquote>
<ol start="4">
<li>最初的报告发给Crowd R进行质量评估，最终报告呈现给顾客。</li>
</ol>
<ul>
<li>额外的众包支出都被cover在了原有的production cycle中，continuous improvement cycle是基于其上新增的audio-2-report pipeline</li>
<li>两组crowd产生的text file会被记录到报告数据库中，用于搭建语言模型(LM)。LM基于标准开发集和过往LM的表现进行打分，如果分数有提高，LM会被用于改善ASR系统。ASR基于逐字逐句翻译的口述书面稿进行训练，最终生成标准的电子医用报告(EMR)</li>
</ul>
<h3 id="结果讨论"><a href="#结果讨论" class="headerlink" title="结果讨论"></a>结果讨论</h3><p>我们使用的ASR系统基于具有40维的MFCC，fMLLR，ivector，SAT，GMM-HMM预训练以及基于深度神经网络训练的声学模型，经过数百小时的医学听写音频训练。语言模型使用four-grams with Kneser-Ney进行平滑和插入相关语句来最大程度地减少困惑。</p>
<p>本文中描述的“持续改进循环系统”主要是针对语言模型的适应和调整而设计的，并且事实证明，该过程非常有效，而且无需增加人工开销。通过严格地使用持续改进周期，可以将最初受过1亿多个训练的医学听写系统从原始的34.1％错误率改进为10.4％。进一步的增强包括声学模型的适应性以及对自动格式化组件及其反向组件的调整。</p>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>crowdsourcing</tag>
        <tag>deep learning</tag>
        <tag>artificial intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title>Intro to datasets</title>
    <url>/2020/02/04/2020-02-04-Intro-to-datasets/</url>
    <content><![CDATA[<h3 id="Simulation-vs-Experiments"><a href="#Simulation-vs-Experiments" class="headerlink" title="Simulation vs Experiments"></a>Simulation vs Experiments</h3><p>在虚拟的系统里我们常进行模拟，例如网络协议和储存性能。</p>
<p>在一些基于现实场景而虚拟构建的模型中我们进行试验，比如众包和机器学习，</p>
<p>当然两者的差异还体现在人为的设定和调参方面等。</p>
<a id="more"></a>

<h3 id="Experiments-in-crowdsourcing"><a href="#Experiments-in-crowdsourcing" class="headerlink" title="Experiments in crowdsourcing"></a>Experiments in crowdsourcing</h3><p>众包要进行实验有三种方式，一是通过传统的众包平台如AMT完成HIT(human intelligence task)，二是在问卷网站上回答一系列的问题，三是通过空间众包 spatial crowdsourcing。它在<a href="https://link.springer.com/article/10.1007/s00778-019-00568-7" target="_blank" rel="noopener">Spatial crowdsourcing: a survey</a>的定义是 tasks are spatiotemporal and must be completed at a specific location and time，文中提到的共享单车和几个共享数据的地图软件的成功全是仰仗这个新的众包形式的诞生。</p>
<p>正因如此，datasets for spatial crowdsourcing 应运而生（文中给了许多数据集的地址），以下是一些数据集的介绍</p>
<h4 id="Foursquare-Dataset"><a href="#Foursquare-Dataset" class="headerlink" title="Foursquare Dataset"></a>Foursquare Dataset</h4><p>这是一个记录了纽约和东京各酒店用户的地理位置等信息的数据集。</p>
<h4 id="CMCC-Dataset"><a href="#CMCC-Dataset" class="headerlink" title="CMCC Dataset"></a>CMCC Dataset</h4><p>这是一个记录了用户移动信息的数据集，精确到出入某地点到分钟。</p>
<h4 id="D4D-Dataset"><a href="#D4D-Dataset" class="headerlink" title="D4D Dataset"></a>D4D Dataset</h4><p>“D4D” = “Data for Development”, 这是一个记录了匿名电话地理位置信息的数据集</p>
<h4 id="Gowalla-Dataset"><a href="#Gowalla-Dataset" class="headerlink" title="Gowalla Dataset"></a>Gowalla Dataset</h4><ul>
<li>记录了地理信息：社区，娱乐，食品，夜生活，户外活动，购物和旅行，每个主要类别都包含几个子类别</li>
<li>收集用户个人资料，用户社交关系（来自Facebook），个人资料和用户的酒店入住信息</li>
</ul>
<h3 id="Suggestion-on-Data-Processing"><a href="#Suggestion-on-Data-Processing" class="headerlink" title="Suggestion on Data Processing"></a>Suggestion on Data Processing</h3><ul>
<li>数据清洗很重要，有助于找到时空的逻辑联系</li>
<li>对于缺失数据需要小心对待</li>
<li>善用Matlab（&gt;Python）</li>
</ul>
]]></content>
      <categories>
        <category>科研</category>
      </categories>
      <tags>
        <tag>data</tag>
        <tag>crowdsourcing</tag>
      </tags>
  </entry>
  <entry>
    <title>2019.12-2020.1</title>
    <url>/2020/02/02/2019-12-2020-1/</url>
    <content><![CDATA[<h3 id="PC-升级"><a href="#PC-升级" class="headerlink" title="PC 升级"></a>PC 升级</h3><p>家里的台式从高考完服役到现在已经有两年半了，正巧实习要在家待上半年，又种草了NZXT的机箱（主要是风扇太好看了），于是就顺理成章的下单新玩具了。虽然早就听说作为AMD员工购买公司产品可以享受优惠，不过在了解了一番之后还是被繁琐的报销流程劝退了。</p>
<p><img src="https://raw.githubusercontent.com/graveszhang/Img-Host/master/DSC07484.jpg" alt=""></p>
<a id="more"></a>

<p>这已经不是我第一次装机了，19年暑假的时候由于迫切想在寝室玩到2K20，而手上只有两台MacBook Pro，于是浪费了很多钱和精力在支持DX12的虚拟机、显卡坞上等等，最后发现效果都不尽如人意，还是老老实实装了台式。这次更新完主要配置如下</p>
<ul>
<li><a href="https://www.amazon.com/AMD-Ryzen-3700X-16-Thread-Processor/dp/B07SXMZLPK/ref=sr_1_2?keywords=ryzen+3700x&qid=1580645435&s=electronics&sr=1-2" target="_blank" rel="noopener">AMD Ryzen 3700X</a></li>
<li><a href="https://www.amazon.com/CORSAIR-Vengeance-PC4-28800-Desktop-Memory-Black/dp/B081BTFN1B/ref=sr_1_3?keywords=corsair+64gb+ddr4+3600&qid=1580645416&s=electronics&sr=1-3" target="_blank" rel="noopener">Corsair RGB Pro 32GBx2 DDR4 3600</a></li>
<li><a href="https://www.amazon.com/MSI-Gaming-RTX-2080-Super/dp/B07VDMGYGZ/ref=sr_1_2?keywords=rtx+2080+msi&qid=1580645368&s=electronics&sr=1-2" target="_blank" rel="noopener">Geforce RTX 2080 Gaming X Trio | MSI</a></li>
<li><a href="https://www.amazon.com/Samsung-970-EVO-1TB-MZ-V7E1T0BW/dp/B07BN217QG" target="_blank" rel="noopener">Samsung 970 EVO SSD 1TB - M.2</a></li>
<li><a href="https://www.amazon.com/Asus-Prime-X570-Pro-Ryzen-Motherboard/dp/B07SW925DQ/ref=sr_1_3?keywords=amd+ryzen3+motherboard&qid=1580645594&s=electronics&sr=1-3" target="_blank" rel="noopener">ASUS X570-Pro Motherboard</a></li>
<li><a href="https://www.amazon.com/NZXT-H510-Elite-Dual-Tempered-Water-Cooling/dp/B07T7L875Z/ref=sr_1_2?crid=PLO1FSOHCTX3&keywords=nzxt%2Bh510%2Belite&qid=1580645636&s=electronics&sprefix=NZXT%2B%2Celectronics%2C453&sr=1-2&th=1" target="_blank" rel="noopener">NZXT H510 Elite</a></li>
</ul>
<p>其实电脑配置多少，和玩游戏的需求是两码事。随着年纪增大，我越发觉得游戏于我来说社交的作用已经远远大于一切。多数时间我只是买下感兴趣的游戏，进去体验一番，于是卸载，或再不打开，若要我去思考购置顶配游戏主机和花大笔钱在不怎么玩的游戏上的意义，对我来说是本末倒置了。当然，这只是我个人的思考。</p>
<h3 id="伊苏8-｜-蜘蛛侠"><a href="#伊苏8-｜-蜘蛛侠" class="headerlink" title="伊苏8 ｜ 蜘蛛侠"></a>伊苏8 ｜ 蜘蛛侠</h3><p>前面提到我是一个不怎么认真玩游戏的人，多数游戏只是追求体验罢了，但没想到PS4的奖杯系统还是Push了我一把好好体验游戏。这个假期先是较完美的通关了《底特律：变成人类》，又白金了去年通关的《伊苏8》和《蜘蛛侠》。</p>
<p><img src="https://github.com/graveszhang/Img-Host/blob/master/IMG_0403.JPG?raw=true" alt=""></p>
<p>我有些特别的感受，尤其是在《蜘蛛侠》里刷完曼哈顿的反派据点之后…</p>
<p>感觉特别的失望，毫无乐趣可言。</p>
<p>就是那种经行漫长的等候，却只是毫无波澜的添上一道句点。</p>
<p>虽说这几个游戏白金的难度都不是特别大，但是高重复度的任务和反复担心错过奖杯的心情已经严重影响了我的游戏体验。</p>
<p>话这么说，以后遇到相似难度的白金神作，可能还是忍不住刷一个完美通关，这也许就是100%这个数字的魅力吧。</p>
<h3 id="神秘海域4-盗贼末路"><a href="#神秘海域4-盗贼末路" class="headerlink" title="神秘海域4 盗贼末路"></a>神秘海域4 盗贼末路</h3><p>16年就购买的游戏，直到这个冬天才真正玩上一会。</p>
<p>先是被画面震撼，接着被剧情征服。</p>
<p>三个监狱里的男人出逃后重新聚首，又站到了同一艘船上。</p>
<p>拉夫为了野心和名望，山姆为了梦想，</p>
<p>而奈森是如此的单纯——</p>
<p>他只是享受探险过程的乐趣。</p>
<p><img src="https://github.com/graveszhang/Img-Host/blob/master/IMG_0435.JPG?raw=true" alt=""></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>game</tag>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title>关于本站</title>
    <url>/2020/02/02/About%20this%20blog/</url>
    <content><![CDATA[<div class="note success">
            <p>建站历程</p><ul><li>2020.01.31 - 部署Hexo，主题采用NexT-5.1.4</li><li>2020.02.02 - 博客添加关于页面</li><li>2020.02.02 - 博客主题升级至NexT-7.7.1</li><li>2020.02.03 - 博客添加近期文章，删除相册</li></ul>
          </div>]]></content>
      <categories>
        <category>建站</category>
      </categories>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/02/01/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<a id="more"></a>

<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>建站</category>
      </categories>
  </entry>
</search>
